{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "from backbone import EfficientDetBackbone\n",
    "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
    "from utils.utils import preprocess, invert_affine, postprocess, boolean_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_coef = 0\n",
    "nms_threshold = 0.5\n",
    "use_cuda = True\n",
    "gpu = 0\n",
    "override_prev_results = True\n",
    "float16 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = f'weights/efficientdet-d0_1_18000.pth' \n",
    "num_gpus=1\n",
    "\n",
    "# mean and std in RGB order\n",
    "mean= [0.485, 0.456, 0.406]\n",
    "std= [0.229, 0.224, 0.225]\n",
    "\n",
    "# coco anchors\n",
    "anchors_scales= '[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]'\n",
    "anchors_ratios= '[(1.0, 1.0), (1.4, 0.7), (0.7, 1.4)]'\n",
    "\n",
    "obj_list = ['3m''abus','accenture','adidas','adidas1','adidas_text','airhawk','airness','aldi','aldi_text','alfaromeo','allett','allianz','allianz_text',\n",
    "            'aluratek','aluratek_text','amazon','amcrest','amcrest_text','americanexpress','americanexpress_text','android','anz','anz_text',\n",
    "            'apc','apecase','apple','aquapac_text','aral','armani','armitron','aspirin','asus','at_and_t','athalon','audi','audi_text',\n",
    "            'axa','bacardi','bankofamerica','bankofamerica_text','barbie','barclays','base','basf','batman','bayer','bbc','bbva',\n",
    "          'becks','bellataylor','bellodigital','bellodigital_text','bem','benrus','bershka','bfgoodrich','bik','bionade',\n",
    "            'blackmores','blizzardentertainment','bmw','boeing','boeing_text','bosch','bosch_text','bottegaveneta','bridgestone','bridgestone_text','budweiser','budweiser_text','bulgari','burgerking',\n",
    "            'burgerking_text','calvinklein','canon','carglass','carlsberg','carters','cartier','caterpillar','chanel','chanel_text','cheetos','chevrolet',\n",
    "            'chevrolet_text','chevron','chickfila','chimay','chiquita','cisco','citi','citroen','citroen_text','coach','cocacola','coke','colgate','comedycentral','converse','corona','corona_text',\n",
    "            'costa','costco','cpa_australia','cvs','cvspharmacy','danone','dexia','dhl','disney','doritos','drpepper','dunkindonuts','ebay','ec','erdinger','espn','esso','esso_text',\n",
    "            'evernote','facebook','fedex','ferrari','firefox','firelli','fly_emirates','ford','fosters','fritolay','fritos',\n",
    "            'gap','generalelectric','gildan','gillette','goodyear','google','gucci','guinness','hanes','head','head_text','heineken','heineken_text','heraldsun','hermes','hersheys',\n",
    "            'hh','hisense','hm','homedepot','homedepot_text','honda','honda_text','hp','hsbc','hsbc_text','huawei','huawei_text','hyundai','hyundai_text','ibm','ikea','infiniti''infiniti_text',\n",
    "            'intel','internetexplorer','jackinthebox','jacobscreek','jagermeister','jcrew','jello','johnnywalker','jurlique','kelloggs',\n",
    "            'kfc','kia','kitkat','kodak','kraft','lacoste','lacoste_text','lamborghini','lays','lego','levis','lexus','lexus_text',\n",
    "            'lg','londonunderground','loreal','lotto','luxottica','lv','marlboro','marlboro_fig','marlboro_text','maserati','mastercard','maxwellhouse',\n",
    "            'maxxis','mccafe','mcdonalds','mcdonalds_text','medibank','mercedesbenz','mercedesbenz_text','michelin','microsoft','milka',\n",
    "            'millerhighlife','mini','miraclewhip','mitsubishi','mk','mobil','motorola','mtv','nasa','nb','nbc','nescafe','netflix','nike',\n",
    "            'nike_text','nintendo','nissan','nissan_text','nivea','northface','nvidia','obey','olympics','opel','optus','optus_yes','oracle','pampers','panasonic'\n",
    "            ,'paulaner','pepsi','pepsi_text','pepsi_text1','philadelphia','philips','pizzahut','pizzahut_hut','planters','playstation',\n",
    "            'poloralphlauren','porsche','porsche_text','prada','puma','puma_text','quick','rbc','recycling','redbull','redbull_text','reebok','reebok1','reebok_text',\n",
    "            'reeses','renault','republican','rittersport','rolex','rolex_text','ruffles','samsung','santander','santander_text','sap','schwinn',\n",
    "            'scion_text','sega','select','shell','shell_text','shell_text1','siemens','singha','skechers','sony','soundcloud','soundrop',\n",
    "            'spar','spar_text','spiderman','sprite','standard_liege','starbucks','stellaartois','subaru','subway','sunchips',\n",
    "            'superman','supreme','suzuki','t-mobile','tacobell','target','target_text','teslamotors','texaco','thomsonreuters',\n",
    "            'tigerwash','timberland','tissot','tnt','tommyhilfiger','tostitos','total','toyota','toyota_text','tsingtao','twitter','umbro',\n",
    "            'underarmour','unicef','uniqlo','uniqlo1','unitednations','ups','us_president','vaio','velveeta','venus','verizon',\n",
    "            'verizon_text','visa','vodafone','volkswagen','volkswagen_text','volvo','walmart','walmart_text','warnerbros','wellsfargo',\n",
    "            'wellsfargo_text','wii','williamhill','windows','wordpress','xbox','yahoo','yamaha','yonex','yonex_text','youtube','zara']\n",
    "\n",
    "input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536, 1536]\n",
    "\n",
    "\n",
    "def evaluate_coco(img_path, set_name, image_ids, coco, model, threshold=0.05):\n",
    "    results = []\n",
    "\n",
    "    regressBoxes = BBoxTransform()\n",
    "    clipBoxes = ClipBoxes()\n",
    "\n",
    "    for image_id in tqdm(image_ids):\n",
    "        image_info = coco.loadImgs(image_id)[0]\n",
    "        image_path = img_path + image_info['file_name']\n",
    "\n",
    "        ori_imgs, framed_imgs, framed_metas = preprocess(image_path, max_size=input_sizes[compound_coef])\n",
    "        x = torch.from_numpy(framed_imgs[0])\n",
    "\n",
    "        if use_cuda:\n",
    "            x = x.cuda(gpu)\n",
    "            x = x.float()\n",
    "        else:\n",
    "            x = x.float()\n",
    "\n",
    "        x = x.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "        features, regression, classification, anchors = model(x)\n",
    "\n",
    "        preds = postprocess(x,\n",
    "                            anchors, regression, classification,\n",
    "                            regressBoxes, clipBoxes,\n",
    "                            threshold, nms_threshold)\n",
    "        \n",
    "        if not preds:\n",
    "            continue\n",
    "\n",
    "        preds = invert_affine(framed_metas, preds)[0]\n",
    "\n",
    "        scores = preds['scores']\n",
    "        class_ids = preds['class_ids']\n",
    "        rois = preds['rois']\n",
    "\n",
    "        if rois.shape[0] > 0:\n",
    "            # x1,y1,x2,y2 -> x1,y1,w,h\n",
    "            rois[:, 2] -= rois[:, 0]\n",
    "            rois[:, 3] -= rois[:, 1]\n",
    "\n",
    "            bbox_score = scores\n",
    "\n",
    "            for roi_id in range(rois.shape[0]):\n",
    "                score = float(bbox_score[roi_id])\n",
    "                label = int(class_ids[roi_id])\n",
    "                box = rois[roi_id, :]\n",
    "\n",
    "                image_result = {\n",
    "                    'image_id': image_id,\n",
    "                    'category_id': label + 1,\n",
    "                    'score': float(score),\n",
    "                    'bbox': box.tolist(),\n",
    "                }\n",
    "\n",
    "                results.append(image_result)\n",
    "\n",
    "    if not len(results):\n",
    "        raise Exception('the model does not provide any valid output, check model architecture and the data input')\n",
    "\n",
    "    # write output\n",
    "    filepath = f'{set_name}_bbox_results.json'\n",
    "    if os.path.exists(filepath):\n",
    "        os.remove(filepath)\n",
    "    json.dump(results, open(filepath, 'w'), indent=4)\n",
    "\n",
    "\n",
    "def _eval(coco_gt, image_ids, pred_json_path):\n",
    "    # load results in COCO evaluation tool\n",
    "    coco_pred = coco_gt.loadRes(pred_json_path)\n",
    "\n",
    "    # run COCO evaluation\n",
    "    print('BBox')\n",
    "    coco_eval = COCOeval(coco_gt, coco_pred, 'bbox')\n",
    "    coco_eval.params.imgIds = image_ids\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.36s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:36<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "BBox\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=6.07s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.56s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.227\n"
     ]
    }
   ],
   "source": [
    "SET_NAME = 'JPEGImages'\n",
    "VAL_GT = f'Annotations\\instances_JPEGImages.json'\n",
    "VAL_IMGS = f'JPEGImages\\\\'\n",
    "\n",
    "MAX_IMAGES = 1000\n",
    "coco_gt = COCO(VAL_GT)\n",
    "image_ids = coco_gt.getImgIds()[:MAX_IMAGES]\n",
    "\n",
    "if override_prev_results or not os.path.exists(f'{SET_NAME}_bbox_results.json'):\n",
    "    model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list)+1,\n",
    "                                 ratios=eval(anchors_ratios), scales=eval(anchors_scales))\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu')))\n",
    "    model.requires_grad_(False)\n",
    "    model.eval()\n",
    "\n",
    "    if use_cuda:\n",
    "        model.cuda(gpu)\n",
    "\n",
    "    evaluate_coco(VAL_IMGS, SET_NAME, image_ids, coco_gt, model)\n",
    "\n",
    "_eval(coco_gt, image_ids, f'{SET_NAME}_bbox_results.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The metrics used for evaluating the models are IoU, Average precision and recall.\n",
    "*  in AP, we collect all the predictions made for apples in all the images and rank it in descending order according to the predicted confidence level.\n",
    "* IOU is a metric that finds the difference between ground truth annotations and predicted bounding boxes. In object detection, the model predicts multiple bounding boxes for each object, and based on the confidence scores of each bounding box it removes unnecessary boxes based on its threshold value. \n",
    "* mAP iou=0.5 represents the model has used 0.5 threshold value to remove unnecessary bounding boxes, it is the standard threshold value for most of the models.\n",
    "* mAP iou=0.75 represents the model has used 0.75 threshold value, By using this we can get accurate results by removing bounding boxes with less than 25% of the intersection with ground truth image.\n",
    "* mAP small represents the model has given mAP score based on smaller objects in the data.\n",
    "* mAP large represents the model has given mAP score based on larger objects in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
